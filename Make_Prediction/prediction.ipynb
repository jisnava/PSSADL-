{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "prediction_only.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnSPtBk2myT0"
      },
      "source": [
        "The saved model and the sample text file must be uploaded to the drive.\\\n",
        "The path must be updated in all lines in the below code where it is written \"change path\".\\\n",
        "The imtermediate files are saved in the same path itself. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9VxmQ_nlCcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e708d0-3a4f-47d7-b17a-e04604a04e38"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gHcW3ZGkWKs",
        "outputId": "d6a40c6f-6d06-4468-9995-ea364c10564f"
      },
      "source": [
        "#Code to test individual files from the test set using the saved model weights\n",
        "#imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM, TimeDistributed,Bidirectional\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import time\n",
        "#start = time.time()\n",
        "\n",
        "def userformat_to_numpytextformat(pathfirsttext): #Convert to text for numpy format\n",
        "    f = open(pathfirsttext, 'r')\n",
        "    t = open('/content/numpytext_format_sys.txt', 'w')      #output file name-change path\n",
        "    classes = {'A':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6, 'H':7, 'I':8, 'K':9, 'L':10, 'M':11,'N':12, 'P':13, 'Q':14, 'R':15, 'S':16, 'T':17, 'V':18, 'W':19, 'Y':20}\n",
        "    def make_one_hot(n):\n",
        "        st = ''\n",
        "        i = 1\n",
        "        while (i <= 20):\n",
        "            if(i == n):\n",
        "                st += '1'\n",
        "            else:\n",
        "                st += '0'\n",
        "            if(i != 20):\n",
        "                st += ' '\n",
        "            i += 1\n",
        "        return st\n",
        "\n",
        "    def fill_z(n):\n",
        "        i = 1\n",
        "        st = ''\n",
        "        while (i <= n):\n",
        "            st += make_one_hot(0)\n",
        "            st += ' 0 0 0 0 0 0'\n",
        "            if(i != n):\n",
        "                st += '\\n'\n",
        "            i += 1\n",
        "        return st\n",
        "\n",
        "    line_count = 0\n",
        "\n",
        "    while True:\n",
        "        line = f.readline()\n",
        "        #line_end = o.readline()\n",
        "        if not line:\n",
        "            break\n",
        "\n",
        "        if 'END' in line:\n",
        "            if(line_count < 500):\n",
        "                t.write(fill_z(500 - line_count))\n",
        "                t.write('\\n')\n",
        "            line_count = 0\n",
        "        \n",
        "        else:\n",
        "            line_count += 1\n",
        "            out = line.replace(\"\\n\", \"\").replace(\"\\t\", \"\").split(' ')\n",
        "            #print(out)\n",
        "            c = classes[out[0]]\n",
        "            t.write(make_one_hot(c))\n",
        "            for x in range(1, len(out)):\n",
        "                y = str(out[x]).strip()\n",
        "                if(y != ''):\n",
        "                    t.write(\" \" + str(y))\n",
        "                    #print(y)\n",
        "            t.write(\"\\n\")\n",
        "\n",
        "\n",
        "def gettext(filepath): \n",
        "  txt = open(filepath, encoding='utf-8-sig')\n",
        "  batches = 1           \n",
        "  l = 0            \n",
        "  x = []     \n",
        "  y = []     \n",
        "  while True:\n",
        "    line = txt.readline()\n",
        "    if (not line):\n",
        "      break \n",
        "    w = line.split(' ')\n",
        "    for i in w[:20]:\n",
        "      #print(type(i))\n",
        "      x.append(int(i))\n",
        "    for c in w[20:23]:\n",
        "      x.append(float(c)) \n",
        "    l += 1\n",
        "    if l == 500:\n",
        "      l = 0\n",
        "  x = np.array(x)\n",
        "  x2 = x.reshape(batches, 500, 23)\n",
        "  x2s = batches * 500 * 23\n",
        "  x2 = x.reshape(x2s)\n",
        "  #np.save('/bench_sample.npy', x2)\n",
        "  return x2\n",
        " \n",
        "\n",
        "def testing_protein(numpyfile, act_len): #Make predictions\n",
        "    x_test=np.load(numpyfile)\n",
        "    #-----------------------------------------------------------------------------------------\n",
        "    #Loading test set (189 proteins) from the mounted Google drive OR you can load this from your current working directory\n",
        "    #x_test=np.load('/content/drive/MyDrive/CNN_for_STR_ASSIGNMENT_DATA_and_CODES/bench_193x500x23_xyzjune21.npy')\n",
        "    #y_test=np.load('/content/drive/MyDrive/CNN_for_STR_ASSIGNMENT_DATA_and_CODES/bench_labels_193x500x3_xyzjune21.npy')\n",
        "    #print(\"x_test: \" + str(x_test.shape))\n",
        "    #x_test and y_test represents benchmarked set throughout the code(coordinates and labels respectively)\n",
        "    #----------------------------------------------------------------------------------------\n",
        "    #Reshape the test set-to match the expected dimensions for first CNN layer\n",
        "    x_test = x_test.reshape(1, 500, 23, 1)\n",
        "    #y_test = y_test.reshape(189, 500, 3)\n",
        "    #-----------------------------------------------------------------------------------------\n",
        "    #Load the saved model(2DCNN-BLSTM)\n",
        "    #!pip install keras #if needed\n",
        "    new_model = load_model('/content/drive/MyDrive/CNN_for_STR_ASSIGNMENT_DATA_and_CODES/my_model_full9624Accuracy') #saved model- change path\n",
        "    #new_model.summary() # To see the model summary\n",
        "    #resultbenchmarkCNNBLSTM = new_model.evaluate(x_test, y_test) # Accuracy on benchmark set(Test set I)- Evaluation for entire test set(not for individual samples)\n",
        "    #----------------------------------------------------------------------------------------\n",
        "    #Evaluation on a single protein\n",
        "    #print(x_test[0].shape)\n",
        "    ti = 2 #third protein in test set\n",
        "    test_protein=x_test[0].reshape(1, 500, 23, 1)\n",
        "    #print(test_protein.shape)\n",
        "    preds = new_model.predict(test_protein) #Take a single protein to test and reshape it\n",
        "    label_index = np.argmax(preds, axis=2)\n",
        "    labels = [1, 0, 0, 0, 1, 0, 0, 0, 1]\n",
        "    labels = np.array(labels)\n",
        "    labels = labels.reshape(3, 3)\n",
        "    #print(labels)\n",
        "    act_len=act_len-1\n",
        "    results=[]\n",
        "    #print(\"Mismatch in classes: \" + str(x) + \"\\nLength of sequence: \" + str(t))\n",
        "    #print(\"Length of sequence: \" + str(t))\n",
        "    #print(\"Accuracy: \" + str(((t-x)/t)*100) + \"%\")\n",
        "    for k in range(0,act_len):\n",
        "      if (label_index[0][k])==0:\n",
        "        #print(\"H\",end=' ')\n",
        "        results.append(\"H\")\n",
        "      if (label_index[0][k])==1:\n",
        "        #print(\"E\",end=' ')\n",
        "        results.append(\"E\")\n",
        "      if (label_index[0][k])==2:\n",
        "        #print(\"C\",end=' ')\n",
        "        results.append(\"C\")\n",
        "    return(results)\n",
        "\n",
        "userformat_to_numpytextformat('/content/text_format_sample_1.txt') #change path\n",
        "fp=open('/content/text_format_sample_1.txt','r') #change path\n",
        "lenf=len(fp.readlines())\n",
        "#print(lenf)\n",
        "x3=gettext('/content/numpytext_format_sys.txt')  #change path\n",
        "np.save('/content/bench_sample_2_sys.npy', x3)  #saving in numpy format  #change path\n",
        "res=testing_protein('/content/bench_sample_2_sys.npy',lenf)  #change path\n",
        "print(\"\\n\")\n",
        "print(\"The assignments for the given file are:\")\n",
        "print(' '.join(res))\n",
        "#end = time.time()\n",
        "#print({end-start})\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n",
            "\n",
            "\n",
            "The assignments for the given file are:\n",
            "C E E E E C C E E E E C C C C E E E E E E E C C H H H H C E C C E C C H H H H H H H H H H H H H H C C C C E E E E E C C C C C C C C C C C C H H H H H H H H H H H H H H H H H H C C C E E E E E E C C H H H H H H H H H C C C C E E E E C C C C C C C C H H H H H H H H C C C E E E E E C C C C C C C C C C C C C C C C H H H H H H H H H H H H H H H H H H C C C C H H H E E E E C C C C C C C C H H H H H H H H H C H H H H H H H C C C E E E E C C C C H H H H H H H C C C C C C C H H H H H H H H H H H H H C C C C E E E E C C H H H H H H H H H H H H H H H H C C C C C C C C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWa4Z3JxkrRt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}